# seq2seq
Sequence to sequence network implementation in Pytorch

1. simple_seq2seq.py: This code contains the implementation of paper [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/pdf/1409.3215.pdf)
2. phrase_seq2seq.py: This code contains the implementation of paper [Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation](https://arxiv.org/pdf/1406.1078.pdf)
3. attention_seq2seq.py: This code contains the implementation of paper [Neural Machine translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
4. padded_seq2seq.py: This code contains the usage of padded sequences and masking
5. transformer.py: This code contains the implementation of paper [Attention is All You Need](https://arxiv.org/abs/1706.03762)
6. BERT_basic.py: This code contains the implementation of paper [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)
